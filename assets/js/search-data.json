{
  
    
        "post0": {
            "title": "Hello blog !",
            "content": "Why ? . I created this blog after reading chapter 2 of fastai’s book, teaching deep learning with a top down approach, where they recommended starting a blog. . . I really recommend checking their tutorials and courses, they are great I don’t expect any clear content to start with. This is also a way to help me learn and get things sorted out inside my head. But hey, if you are reading this, you may be in the same situation and can get to learn along with me ;). . Content to expect . This will be a list of what I think will appear on this blog in the future, based on what I am currently doing / learning and what I want to learn in the future. . Machine learning Deep learning | deep reinforcement learning | generative modeling | others | . | Some maths1 | Rambling about topics such as: Rocket Science and other science mystery things (sounds scary) | AI | Engineering and technology stuff | . | . Hope you didn’t feel like waisting your time reading this first post. See you soon ! . I recently ordered my first math book and I intend to learn and understand math more deeply &#8617; . |",
            "url": "https://jonathan-sands.com/markdown/2020/09/23/first_post.html",
            "relUrl": "/markdown/2020/09/23/first_post.html",
            "date": " • Sep 23, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Building a CNN recognizing furniture from different Louis periods",
            "content": "Context . This project was done after reading chapter 2 of fastai&#39;s book. It aims at classifying furniture from 3 different eras : . Louis XIV | Louis XV | Louis XVI | . The idea came from a friend of mine telling me there once was an endless debate at lunch about which era a particular piece of furniture came from. . Content . This notebook will take you through my building and deployment process using the fastai library. If you don&#39;t care about this and just want to check out the final result, please head here. . Building the dataset . To build the dataset, I used fatkun batch download image chrome plugin. There are many other ways to scrap the web for images, but in my case it turns out typing Louis XIV furniture (or should I say mobilier Louis XIV in french since this is a french thing) on Google image gives me a bunch of furniture from all eras. I found at that pinterest has some pretty good collections of images (for example here for Louis XIV styled furniture). It turns out this plugin makes it easy to go on a page then download every images from it, including trash (but you have the ability to remove it before downloading). I recommend you to go on every website/page you need to build your data before downloading, since the plugin detects duplicates (also avoiding the trash images time and time again). . I put each type of images in it&#39;s own folder as you can see. . path = Path(&#39;data/train&#39;) path.ls() . (#4) [Path(&#39;data/train/XV&#39;),Path(&#39;data/train/XIII&#39;),Path(&#39;data/train/XVI&#39;),Path(&#39;data/train/XIV&#39;)] . Cleaning up . Let&#39;s remove corrupted images before moving on. . fns = get_image_files(path) # gets all the image files recursively in path failed = verify_images(fns) failed . █ . (#0) [] . As you can see, our dataset doesn&#39;t have any, and I am not sure if it can happen while using this plugin. But if you ever do have some, execute the next step. . failed.map(Path.unlink) . (#0) [] . From Data to DataLoaders . You should really go an read the chapter from the book if you want to understand what I am doing. I am basically, copy pasting their stuff, even this title is the same ! . furniture = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=1), # Fixed seed for tuning hyperparameters get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = furniture.dataloaders(path) . Let&#39;s take a look at some of does images ! . dls.valid.show_batch(max_n=4, nrows=1) . Okay, looking good ! But we have lots of data. . len(fns) . 2052 . And among this data are probably some mislabeled ones and some that aren&#39;t even furniture ! To help us out in our cleaning process, we will use a quickly trained model. . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time 0 1.752790 0.920795 0.319095 00:06 epoch train_loss valid_loss error_rate time 0 1.079975 0.690126 0.258794 00:07 1 0.904969 0.654678 0.211055 00:07 2 0.726501 0.621098 0.208543 00:07 3 0.610325 0.598395 0.203518 00:07 . Even if we quickly trained our model on a small architecture (resnet18), we can get an idea of what the model has trouble identifying by plotting a confusion matrix. . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . █ . But we haven&#39;t cleaned anything yet so let&#39;s do that ! . cleaner = ImageClassifierCleaner(learn) cleaner . █ . for idx in cleaner.delete(): cleaner.fns[idx].unlink() # Delete files you selected as Delete . for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat) # Change label from mislabeled images . I redid this whole procedure another time, just to be sure. And I probably should do it again. Unfortunately, I am no furniture expert and can&#39;t really relabel mislabeled data so I guess my dataset is full of it. . Training the actual model ! . Now that our dataset is clean (not really haha), we can start training our actual production model ! . path = Path(&#39;data/train&#39;) fns = get_image_files(path) len(fns) . 1992 . Our dataset is smaller now that we removed 60 images ! . furniture = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=1), # Fixed seed for tuning hyperparameters get_y=parent_label, item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) . dls = furniture.dataloaders(path,bs=32) . learn = cnn_learner(dls, resnet50, metrics=error_rate) learn.fine_tune(8, cbs=[ShowGraphCallback()]) . epoch train_loss valid_loss error_rate time . 0 | 1.424473 | 1.235989 | 0.351759 | 00:12 | . epoch train_loss valid_loss error_rate time . 0 | 0.890016 | 0.578133 | 0.193467 | 00:16 | . 1 | 0.728691 | 0.681202 | 0.178392 | 00:16 | . 2 | 0.672835 | 0.601211 | 0.180905 | 00:16 | . 3 | 0.510261 | 0.606285 | 0.175879 | 00:16 | . 4 | 0.341562 | 0.585303 | 0.160804 | 00:16 | . 5 | 0.211855 | 0.521299 | 0.153266 | 00:16 | . 6 | 0.148523 | 0.524159 | 0.135678 | 00:16 | . 7 | 0.126175 | 0.551581 | 0.135678 | 00:16 | . learn.save(&#39;resnet50-13_error_rate&#39;) . Path(&#39;models/resnet50-13_error_rate.pth&#39;) . We used transfer learning, using resnet50 as our pretrained model (resnet50 architecture with pretrained weights from the ImageNet dataset) and a batch size of 32 (since I am training on my personal GPU RTX2060 that couldn&#39;t handle a larger batch size). As you can see, our error_rate on the validation set is aroud 13%, which is not great, but considering our approximate dataset, is understandable. . Making a web app . We are going now to make a notebook app and deploy it. . First let us save our learn object. . learn.export() . path = Path() path.ls(file_exts = &#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . learn_inf = load_learner(path/&#39;export.pkl&#39;) . To make our app, we will use IPython widgets and Voilà. . btn_upload = widgets.FileUpload() out_pl = widgets.Output() lbl_pred = widgets.Label() btn_run = widgets.Button(description=&#39;Classify&#39;) . Let&#39;s define what uploading an image does. . def on_data_change(change): lbl_pred.value = &#39;&#39; img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . btn_upload.observe(on_data_change, names=[&#39;data&#39;]) . display(VBox([widgets.Label(&#39;Select your piece of Louis furniture !&#39;), btn_upload, out_pl, lbl_pred])) . Above is what the user sees when he launches our app. . When uploading an image, the whole thing looks like this ! . Now, we just have to deploy our app ! Voilà can transform you jupyter notebook into a simple working web app. Of course we aren&#39;t transforming this entire notebook but instead this one here. . We are deploying our app on Binder. Check out these documentations on how to use voilà with Binder. . And TADAAAA! That&#39;s all it took ! Check out the working web app . Conclusion . What do I take out of this small project ? . Things that worked great . training | building app | deploying app | . Things that didn&#39;t work great / were hard . getting good data (lots of mislabeled data) | cleaning it up (lots of out-of-domain data) | finding the right number of epoch felt a little random | . Things to look into: . Find a way to get cleaner data | Perhaps use a different slice than default for fine tuning | Make the app cleaner | .",
            "url": "https://jonathan-sands.com/jupyter/fastai/voila/cnn/deep%20learning/2020/09/23/Louis_CNN.html",
            "relUrl": "/jupyter/fastai/voila/cnn/deep%20learning/2020/09/23/Louis_CNN.html",
            "date": " • Sep 23, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jonathan-sands.com/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jonathan-sands.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jonathan-sands.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}